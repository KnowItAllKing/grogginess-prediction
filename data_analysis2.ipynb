{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5210/3783355864.py:3: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  data['date'] = pd.to_datetime(data['ISO8601'], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32   2024-03-31\n",
       "33   2024-04-01\n",
       "34   2024-04-02\n",
       "35   2024-04-03\n",
       "36   2024-04-04\n",
       "37   2024-04-05\n",
       "38   2024-04-06\n",
       "39   2024-04-07\n",
       "40   2024-04-08\n",
       "41   2024-04-09\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person = 'Mark'\n",
    "data = pd.read_csv(f'{person}/autosleep-{person}.csv')\n",
    "data['date'] = pd.to_datetime(data['ISO8601'], errors='coerce')\n",
    "data['date'] = data['date'].apply(lambda x: x.tz_localize(None).normalize() if x is not pd.NaT else pd.NaT)\n",
    "data['year'] = data['date'].dt.year\n",
    "data['month'] = data['date'].dt.month\n",
    "data['day'] = data['date'].dt.day\n",
    "data['inBed_minutes'] = pd.to_timedelta(data['inBed']).dt.total_seconds() / 60\n",
    "data['day_of_week'] = data['date'].dt.dayofweek\n",
    "data['is_weekend'] = data['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "data['date'][len(data) - 10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "  column_mappings = {\n",
    "      'Name': 'name',\n",
    "      'Date': 'date',\n",
    "      'Grogginess': 'grogginess',\n",
    "      'How many alarms did you set?': 'num_alarms',\n",
    "      'What time did you set your first alarm for?': 'first_alarm',\n",
    "      'Did you take sleep-aiding medicine (not weed, ie melatonin/antihystamine)?': 'sleep_medicine',\n",
    "      \"What was the temperature when you woke up? (Don't include Â°F, just the number)\": 'waking_temp',\n",
    "      'Were you intoxicated when you went to sleep?': 'intoxicated',\n",
    "      'Were you sick when you went to sleep?': 'sick',\n",
    "      'Did you eat within an hour of going to bed?': 'eat_before_bed',\n",
    "      'Did you sleep alone?': 'sleep_alone',\n",
    "      'Did you sleep in your own bed/room?': 'own_bed',\n",
    "      'How stressed were you last night?': 'stress',\n",
    "      'Did you use your phone before going to sleep?': 'phone_before_bed',\n",
    "      \"When was the latest you ingested caffeine before going to bed? (Don't answer if N/A)\": 'caffeine_before_bed'\n",
    "  }\n",
    "  \n",
    "  df_renamed = df.rename(columns=column_mappings)\n",
    "  return df_renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppl = rename_columns(pd.read_csv('form.csv'))\n",
    "\n",
    "suppl['date'] = pd.to_datetime(suppl['date'], format='%m/%d/%Y').dt.normalize()\n",
    "\n",
    "\n",
    "def time_to_minutes(time_str):\n",
    "  if pd.isna(time_str) or time_str == '':\n",
    "      return 0\n",
    "  time = pd.to_datetime(time_str, format='%I:%M:%S %p')\n",
    "  return time.hour * 60 + time.minute\n",
    "\n",
    "suppl['first_alarm'] = suppl['first_alarm'].apply(time_to_minutes)\n",
    "suppl['caffeine_before_bed'] = suppl['caffeine_before_bed'].apply(time_to_minutes)\n",
    "lag_periods = 1\n",
    "suppl['grogginess_lag1'] = suppl['grogginess'].shift(lag_periods)\n",
    "suppl = suppl[suppl['name'] == person].fillna(0)\n",
    "# suppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Timestamp', 'name', 'date', 'grogginess', 'num_alarms', 'first_alarm', 'sleep_medicine', 'waking_temp', 'intoxicated', 'sick', 'eat_before_bed', 'sleep_alone', 'own_bed', 'stress', 'phone_before_bed', 'caffeine_before_bed', 'grogginess_lag1', 'ISO8601', 'fromDate', 'toDate', 'bedtime', 'waketime', 'inBed', 'awake', 'fellAsleepIn', 'sessions', 'asleep', 'asleepAvg7', 'efficiency', 'efficiencyAvg7', 'quality', 'qualityAvg7', 'deep', 'deepAvg7', 'sleepBPM', 'sleepBPMAvg7', 'dayBPM', 'dayBPMAvg7', 'wakingBPM', 'wakingBPMAvg7', 'hrv', 'hrvAvg7', 'sleepHRV', 'sleepHRVAvg7', 'SpO2Avg', 'SpO2Min', 'SpO2Max', 'respAvg', 'respMin', 'respMax', 'tags', 'notes', 'year', 'month', 'day', 'inBed_minutes', 'day_of_week', 'is_weekend']\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.merge(suppl, data, on='date', how='inner').fillna(0)\n",
    "\n",
    "\n",
    "column_headers = list(merged_data.columns.values)\n",
    "\n",
    "print(column_headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>grogginess</th>\n",
       "      <th>num_alarms</th>\n",
       "      <th>first_alarm</th>\n",
       "      <th>waking_temp</th>\n",
       "      <th>intoxicated</th>\n",
       "      <th>sick</th>\n",
       "      <th>eat_before_bed</th>\n",
       "      <th>...</th>\n",
       "      <th>respMin</th>\n",
       "      <th>respMax</th>\n",
       "      <th>tags</th>\n",
       "      <th>notes</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>inBed_minutes</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/20/2024 2:28:47</td>\n",
       "      <td>Mark</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>7</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.557312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/20/2024 18:38:08</td>\n",
       "      <td>Mark</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0.348814</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/22/2024 13:31:58</td>\n",
       "      <td>Mark</td>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.527652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/23/2024 14:16:26</td>\n",
       "      <td>Mark</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.786561</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/25/2024 16:45:03</td>\n",
       "      <td>Mark</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.716403</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2/25/2024 16:45:55</td>\n",
       "      <td>Mark</td>\n",
       "      <td>2024-02-25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2/27/2024 3:10:27</td>\n",
       "      <td>Mark</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.449605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2/27/2024 14:30:15</td>\n",
       "      <td>Mark</td>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.519763</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3/7/2024 23:24:11</td>\n",
       "      <td>Mark</td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>7</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.706522</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3/11/2024 0:01:02</td>\n",
       "      <td>Mark</td>\n",
       "      <td>2024-03-10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.133399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  name       date  grogginess  num_alarms  first_alarm  \\\n",
       "0   2/20/2024 2:28:47  Mark 2024-02-19           7    0.666667          0.9   \n",
       "1  2/20/2024 18:38:08  Mark 2024-02-21           6    0.500000          1.0   \n",
       "2  2/22/2024 13:31:58  Mark 2024-02-22           8    0.666667          1.0   \n",
       "3  2/23/2024 14:16:26  Mark 2024-02-23           4    0.000000          0.0   \n",
       "4  2/25/2024 16:45:03  Mark 2024-02-24           7    0.333333          1.0   \n",
       "5  2/25/2024 16:45:55  Mark 2024-02-25           4    0.000000          0.0   \n",
       "6   2/27/2024 3:10:27  Mark 2024-02-26           5    1.000000          0.9   \n",
       "7  2/27/2024 14:30:15  Mark 2024-02-27           7    1.000000          0.9   \n",
       "8   3/7/2024 23:24:11  Mark 2024-03-07           7    0.833333          0.9   \n",
       "9   3/11/2024 0:01:02  Mark 2024-03-10           9    0.833333          0.5   \n",
       "\n",
       "   waking_temp  intoxicated  sick  eat_before_bed  ...   respMin   respMax  \\\n",
       "0     0.931507          0.0   0.0             0.0  ...  0.884615  0.860465   \n",
       "1     0.931507          0.0   0.0             0.0  ...  0.846154  0.767442   \n",
       "2     1.000000          0.0   0.0             0.0  ...  0.884615  0.790698   \n",
       "3     0.958904          1.0   0.0             0.0  ...  1.000000  0.906977   \n",
       "4     0.958904          1.0   0.0             0.0  ...  1.000000  0.883721   \n",
       "5     0.931507          0.0   0.0             0.0  ...  0.846154  0.953488   \n",
       "6     0.931507          0.0   0.0             1.0  ...  0.923077  0.744186   \n",
       "7     0.931507          0.0   0.0             1.0  ...  0.923077  0.767442   \n",
       "8     0.958904          0.0   0.0             0.0  ...  0.846154  1.000000   \n",
       "9     0.945205          0.0   0.0             0.0  ...  0.923077  0.674419   \n",
       "\n",
       "   tags  notes  year month day inBed_minutes day_of_week is_weekend  \n",
       "0   0.0    0.0  2024     2  19      0.557312    0.000000        0.0  \n",
       "1   0.0    0.0  2024     2  21      0.348814    0.333333        0.0  \n",
       "2   0.0    0.0  2024     2  22      0.527652    0.500000        0.0  \n",
       "3   0.0    0.0  2024     2  23      0.786561    0.666667        0.0  \n",
       "4   0.0    0.0  2024     2  24      0.716403    0.833333        1.0  \n",
       "5   0.0    0.0  2024     2  25      0.826087    1.000000        1.0  \n",
       "6   0.0    0.0  2024     2  26      0.449605    0.000000        0.0  \n",
       "7   0.0    0.0  2024     2  27      0.519763    0.166667        0.0  \n",
       "8   0.0    0.0  2024     3   7      0.706522    0.500000        0.0  \n",
       "9   0.0    0.0  2024     3  10      0.133399    1.000000        1.0  \n",
       "\n",
       "[10 rows x 56 columns]"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_normalize = ['sleepBPM', 'sleepBPMAvg7', 'dayBPM', 'dayBPMAvg7', 'wakingBPM', 'wakingBPMAvg7', \n",
    "            'hrv', 'hrvAvg7', 'sleepHRV', 'sleepHRVAvg7', 'SpO2Avg', 'SpO2Min', 'SpO2Max', \n",
    "            'respAvg', 'respMin', 'respMax', 'inBed_minutes', 'day_of_week', 'is_weekend', \n",
    "            'first_alarm', 'num_alarms', 'sleep_medicine', 'waking_temp', 'intoxicated', \n",
    "            'sick', 'eat_before_bed', 'sleep_alone', 'own_bed', 'stress', 'phone_before_bed', \n",
    "            'caffeine_before_bed']\n",
    "\n",
    "\n",
    "for cat in to_normalize:\n",
    "    merged_data[cat] = merged_data[cat] / (merged_data[cat].max())\n",
    "\n",
    "\n",
    "merged_data.dropna(axis=1, inplace=True)\n",
    "merged_data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sleepBPM', \n",
    "            # 'sleepBPMAvg7', \n",
    "            # 'dayBPM', \n",
    "            # 'dayBPMAvg7',\n",
    "              'wakingBPM',\n",
    "              #  'wakingBPMAvg7', \n",
    "            # 'hrv',\n",
    "              # 'hrvAvg7', \n",
    "              # 'sleepHRV', \n",
    "              # 'sleepHRVAvg7', \n",
    "              # 'SpO2Avg', \n",
    "              # 'SpO2Min', 'SpO2Max', \n",
    "            # 'respAvg', 'respMin', 'respMax', \n",
    "            #'year',\n",
    "            #  'month', \n",
    "            #'day', \n",
    "            'inBed_minutes', \n",
    "            # 'day_of_week', \n",
    "            'is_weekend',\n",
    "              ]\n",
    "features += [\n",
    "# 'first_alarm', \n",
    "# 'num_alarms', \n",
    "'sleep_medicine', \n",
    "# 'waking_temp', \n",
    "# 'intoxicated', \n",
    "# 'sick', \n",
    "#'eat_before_bed', \n",
    "# 'sleep_alone',\n",
    "#  'own_bed', \n",
    "# 'stress', \n",
    "'phone_before_bed', \n",
    "'caffeine_before_bed',\n",
    "#  'grogginess_lag1'\n",
    " ]\n",
    "\n",
    "target = ['grogginess']\n",
    "# merged_data[features].head().to_csv('out.csv')\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = [f for f in features if f in merged_data.columns]\n",
    "X = merged_data[features]  # Features\n",
    "y = merged_data[target]  # Assuming you have a target variable\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# split_point = int(len(X) * 0.9)\n",
    "split_point = len(X) - 1\n",
    "X_train, X_test = X[:split_point], X[split_point:]\n",
    "y_train, y_test = y[:split_point], y[split_point:]\n",
    "\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(42)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.set_device(torch.cuda.current_device())\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "batch_size = 32  # Adjust based on your computational resources\n",
    "\n",
    "training_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset=training_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GrogginessModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GrogginessModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size) \n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "input_size = len(features) \n",
    "hidden_size = 5  \n",
    "output_size = 1\n",
    "model = GrogginessModel(input_size, hidden_size, output_size)\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) \n",
    "lambda1 = 0.1\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion):\n",
    "  model.eval()  # Set the model to evaluation mode\n",
    "  total_loss = 0.0\n",
    "  with torch.no_grad():  # No need to track gradients\n",
    "    for inputs, targets in test_loader:\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, targets)\n",
    "      l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "      total_loss += loss + lambda1 * l1_norm\n",
    "      \n",
    "  avg_loss = total_loss / len(test_loader.dataset)\n",
    "  return avg_loss\n",
    "  \n",
    "class EarlyStopping:\n",
    "  def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "    self.patience = patience\n",
    "    self.verbose = verbose\n",
    "    self.counter = 0\n",
    "    self.best_score = None\n",
    "    self.early_stop = False\n",
    "    self.val_loss_min = np.Inf\n",
    "    self.delta = delta\n",
    "    self.path = path\n",
    "\n",
    "  def __call__(self, val_loss, model):\n",
    "    score = -val_loss\n",
    "\n",
    "    if self.best_score is None:\n",
    "      self.best_score = score\n",
    "      self.save_checkpoint(val_loss, model)\n",
    "    elif score < self.best_score + self.delta:\n",
    "      self.counter += 1\n",
    "      # print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "      if self.counter >= self.patience:\n",
    "          self.early_stop = True\n",
    "    else:\n",
    "      self.best_score = score\n",
    "      self.save_checkpoint(val_loss, model)\n",
    "      self.counter = 0\n",
    "\n",
    "  def save_checkpoint(self, val_loss, model):\n",
    "    if self.verbose:\n",
    "      print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "    torch.save(model.state_dict(), self.path)\n",
    "    self.val_loss_min = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000, Loss: 36.9470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1001/100000, Loss: 3.8533\n",
      "Epoch 2001/100000, Loss: 3.4122\n",
      "Epoch 3001/100000, Loss: 3.2252\n",
      "Epoch 4001/100000, Loss: 3.1264\n",
      "Epoch 5001/100000, Loss: 3.0541\n",
      "Epoch 6001/100000, Loss: 2.9992\n",
      "Epoch 7001/100000, Loss: 2.8823\n",
      "Epoch 8001/100000, Loss: 2.6837\n",
      "Epoch 9001/100000, Loss: 2.5389\n",
      "Epoch 10001/100000, Loss: 2.5109\n",
      "Epoch 11001/100000, Loss: 2.5101\n",
      "Epoch 12001/100000, Loss: 2.5100\n",
      "Epoch 13001/100000, Loss: 2.5100\n",
      "Epoch 14001/100000, Loss: 2.5100\n",
      "Epoch 15001/100000, Loss: 2.5100\n",
      "Epoch 16001/100000, Loss: 2.5100\n",
      "Epoch 17001/100000, Loss: 2.5099\n",
      "Epoch 18001/100000, Loss: 2.5100\n",
      "Epoch 19001/100000, Loss: 2.5099\n",
      "Epoch 20001/100000, Loss: 2.5099\n",
      "Epoch 21001/100000, Loss: 2.5100\n",
      "Epoch 22001/100000, Loss: 2.5100\n",
      "Epoch 23001/100000, Loss: 2.5099\n",
      "Epoch 24001/100000, Loss: 2.5099\n",
      "Epoch 25001/100000, Loss: 2.5100\n",
      "Epoch 26001/100000, Loss: 2.5099\n",
      "Epoch 27001/100000, Loss: 2.5100\n",
      "Epoch 28001/100000, Loss: 2.5100\n",
      "Epoch 29001/100000, Loss: 2.5100\n",
      "Epoch 30001/100000, Loss: 2.5099\n",
      "Epoch 31001/100000, Loss: 2.5099\n",
      "Epoch 32001/100000, Loss: 2.5099\n",
      "Epoch 33001/100000, Loss: 2.5101\n",
      "Epoch 34001/100000, Loss: 2.5099\n",
      "Epoch 35001/100000, Loss: 2.5100\n",
      "Epoch 36001/100000, Loss: 2.5101\n",
      "Epoch 37001/100000, Loss: 2.5100\n",
      "Epoch 38001/100000, Loss: 2.5099\n",
      "Epoch 39001/100000, Loss: 2.5100\n",
      "Epoch 40001/100000, Loss: 2.5100\n",
      "Epoch 41001/100000, Loss: 2.5099\n",
      "Epoch 42001/100000, Loss: 2.5100\n",
      "Epoch 43001/100000, Loss: 2.5100\n",
      "Epoch 44001/100000, Loss: 2.5099\n",
      "Epoch 45001/100000, Loss: 2.5100\n",
      "Epoch 46001/100000, Loss: 2.5100\n",
      "Epoch 47001/100000, Loss: 2.5099\n",
      "Epoch 48001/100000, Loss: 2.5099\n",
      "Epoch 49001/100000, Loss: 2.5100\n",
      "Epoch 50001/100000, Loss: 2.5099\n",
      "Epoch 51001/100000, Loss: 2.5100\n",
      "Epoch 52001/100000, Loss: 2.5100\n",
      "Epoch 53001/100000, Loss: 2.5100\n",
      "Epoch 54001/100000, Loss: 2.5099\n",
      "Epoch 55001/100000, Loss: 2.5100\n",
      "Epoch 56001/100000, Loss: 2.5099\n",
      "Epoch 57001/100000, Loss: 2.5099\n",
      "Epoch 58001/100000, Loss: 2.5099\n",
      "Epoch 59001/100000, Loss: 2.5099\n",
      "Epoch 60001/100000, Loss: 2.5100\n",
      "Epoch 61001/100000, Loss: 2.5100\n",
      "Epoch 62001/100000, Loss: 2.5100\n",
      "Epoch 63001/100000, Loss: 2.5100\n",
      "Epoch 64001/100000, Loss: 2.5099\n",
      "Epoch 65001/100000, Loss: 2.5099\n",
      "Epoch 66001/100000, Loss: 2.5100\n",
      "Epoch 67001/100000, Loss: 2.5100\n",
      "Epoch 68001/100000, Loss: 2.5099\n",
      "Epoch 69001/100000, Loss: 2.5099\n",
      "Epoch 70001/100000, Loss: 2.5099\n",
      "Epoch 71001/100000, Loss: 2.5099\n",
      "Epoch 72001/100000, Loss: 2.5100\n",
      "Epoch 73001/100000, Loss: 2.5100\n",
      "Epoch 74001/100000, Loss: 2.5099\n",
      "Epoch 75001/100000, Loss: 2.5100\n",
      "Epoch 76001/100000, Loss: 2.5099\n",
      "Epoch 77001/100000, Loss: 2.5099\n",
      "Epoch 78001/100000, Loss: 2.5099\n",
      "Epoch 79001/100000, Loss: 2.5099\n",
      "Epoch 80001/100000, Loss: 2.5099\n",
      "Epoch 81001/100000, Loss: 2.5100\n",
      "Epoch 82001/100000, Loss: 2.5099\n",
      "Epoch 83001/100000, Loss: 2.5098\n",
      "Epoch 84001/100000, Loss: 2.5099\n",
      "Epoch 85001/100000, Loss: 2.5099\n",
      "Epoch 86001/100000, Loss: 2.5099\n",
      "Epoch 87001/100000, Loss: 2.5099\n",
      "Epoch 88001/100000, Loss: 2.5099\n",
      "Epoch 89001/100000, Loss: 2.5100\n",
      "Epoch 90001/100000, Loss: 2.5099\n",
      "Epoch 91001/100000, Loss: 2.5099\n",
      "Epoch 92001/100000, Loss: 2.5099\n",
      "Epoch 93001/100000, Loss: 2.5099\n",
      "Epoch 94001/100000, Loss: 2.5099\n",
      "Epoch 95001/100000, Loss: 2.5099\n",
      "Epoch 96001/100000, Loss: 2.5099\n",
      "Epoch 97001/100000, Loss: 2.5098\n",
      "Epoch 98001/100000, Loss: 2.5099\n",
      "Epoch 99001/100000, Loss: 2.5099\n"
     ]
    }
   ],
   "source": [
    "epochs = 100000\n",
    "early_stopping = EarlyStopping(patience=1000, verbose=False)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    val_loss = evaluate_model(model, test_loader, criterion)\n",
    "    early_stopping(val_loss, model)\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, targets)  # Compute loss\n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        total_loss = loss + lambda1 * l1_norm\n",
    "        total_loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize\n",
    "        \n",
    "        running_loss += total_loss.item() * inputs.size(0)  # Total loss for the batch\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)  # Average loss for the epoch\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sleepBPM', 'wakingBPM', 'inBed_minutes', 'is_weekend', 'phone_before_bed']\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleepBPM            0.738295\n",
      "wakingBPM           0.777778\n",
      "inBed_minutes       0.711462\n",
      "is_weekend          1.000000\n",
      "phone_before_bed    1.000000\n",
      "Name: 25, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "realtime_data_values = X_test[features].iloc[0]\n",
    "print(realtime_data_values)\n",
    "realtime_data_values = realtime_data_values.tolist()\n",
    "realtime_data_tensor = torch.tensor([realtime_data_values], dtype=torch.float32)  # Wrap in a list to keep dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss: 0.6728\n"
     ]
    }
   ],
   "source": [
    "avg_test_loss = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Average test loss: {avg_test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss: 0.0009\n",
      "tensor([5.9701])\n",
      "    grogginess\n",
      "25           6\n"
     ]
    }
   ],
   "source": [
    "model = GrogginessModel(input_size, hidden_size, output_size)\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "model.eval()\n",
    "\n",
    "total_loss = 0.0\n",
    "for inputs, targets in test_loader:\n",
    "  with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    total_loss += loss.item() * inputs.size(0)\n",
    "    predicted_grogginess = model(realtime_data_tensor)\n",
    "\n",
    "\n",
    "avg_loss = total_loss / len(test_loader.dataset)\n",
    "print(f'Average test loss: {avg_loss:.4f}')\n",
    "print(predicted_grogginess[0])\n",
    "print(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
